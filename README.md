# Aprendizaje por Refuerzo en RobÃ³tica MÃ³vil

## ğŸ“Œ DescripciÃ³n  
Proyecto que implementa **Q-Learning**, **Monte Carlo** y **SARSA** para entrenar un robot mÃ³vil en entornos con obstÃ¡culos. El objetivo es navegar desde un punto inicial hasta un destino optimizando polÃ­ticas de movimiento.

## ğŸ‘¥ Autores  
- **JesÃºs FernÃ¡ndez RodrÃ­guez**  
  `jesferrod1, jesferrod1@gmail.com`  
- **Enrique PÃ©rez Milla**  
  `enrpermil, enrique.perez.milla@gmail.com`  
_Universidad de Sevilla, EspaÃ±a_  

## âš™ï¸ MÃ©todos  
| Algoritmo      | ImplementaciÃ³n | ParÃ¡metros clave |  
|----------------|----------------|------------------|  
| **Q-Learning** | `mdptoolbox`   | Iteraciones (10k-100M), Î³=0.9 |  
| **Monte Carlo**| Custom (Python)| Primera/cada visita, Î³=0.9, 1k iter |  
| **SARSA**      | Custom (Python)| Îµ-voraz, Î±=0.5, Î³=0.9 |  

## ğŸ“Š Resultados  
- **Q-Learning**: PolÃ­ticas mÃ¡s precisas con iteraciones altas (ej. 100M).  
- **Monte Carlo**: Diferencias mÃ­nimas entre variantes por limitaciÃ³n computacional.  
- **SARSA**: Sensible a Î±, pero requiere mÃ¡s iteraciones para converger.  

## ğŸ” Conclusiones  
- âœ… Algoritmos aplicables a problemas reales.  
- âš ï¸ **Alto costo computacional**: Necesidad de optimizaciÃ³n o hardware avanzado.  

## ğŸ“š Referencias  
- [`mdptoolbox`](https://pymdptoolbox.readthedocs.io)  
- Sutton & Barto, *Reinforcement Learning: An Introduction* (MIT Press, 2018).  
